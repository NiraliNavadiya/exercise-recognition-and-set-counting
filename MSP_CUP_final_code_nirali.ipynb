{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21b7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "# import pafy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# from moviepy.editor import *\n",
    "# %matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img, load_img\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import*\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5466f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: pushups\n",
      "pushup_1.mp4\n",
      "pushup_10.mp4\n",
      "pushup_11.mp4\n",
      "pushup_12.mp4\n",
      "pushup_13.mp4\n",
      "pushup_14.mp4\n",
      "pushup_15.mp4\n",
      "pushup_2.mp4\n",
      "pushup_3.mp4\n",
      "pushup_4.mp4\n",
      "pushup_5.mp4\n",
      "pushup_6.mp4\n",
      "pushup_7.mp4\n",
      "pushup_8.mp4\n",
      "pushup_9.mp4\n",
      "Extracting Data of Class: squat\n",
      "squat_10.mp4\n",
      "squat_11.mp4\n",
      "squat_12.mp4\n",
      "squat_13.mp4\n",
      "squat_14.mp4\n",
      "squat_15.mp4\n",
      "squat_2.mp4\n",
      "squat_3.mp4\n",
      "squat_4.mp4\n",
      "squat_5.mp4\n",
      "squat_6.mp4\n",
      "squat_7.mp4\n",
      "squat_8.mp4\n",
      "squat_9.mp4\n",
      "Extracting Data of Class: suryanamaskar\n",
      "suryanamaskar_1.mp4\n",
      "suryanamaskar_10.mp4\n",
      "suryanamaskar_11.mp4\n",
      "suryanamaskar_12.mp4\n",
      "suryanamaskar_13.mp4\n",
      "suryanamaskar_14.mp4\n",
      "suryanamaskar_15.mp4\n",
      "suryanamaskar_2.mp4\n",
      "suryanamaskar_3.mp4\n",
      "suryanamaskar_4.mp4\n",
      "suryanamaskar_5.mp4\n",
      "suryanamaskar_6.mp4\n",
      "suryanamaskar_7.mp4\n",
      "suryanamaskar_8.mp4\n",
      "suryanamaskar_9.mp4\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATASET_DIR  = 'E:/20_exercise'\n",
    "CLASSES_LIST = [\"pushups\", \"squat\", \"suryanamaskar\" ]\n",
    "SEQUENCE_LENGTH = 500\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "\n",
    "\n",
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)\n",
    "\n",
    "# DATASET_DIR  = \"E:\\\\20_exercise\"\n",
    "# CLASSES_LIST = [\"pushups\", \"squat\", \"suryanamaskar\" ]\n",
    "# SEQUENCE_LENGTH = 250\n",
    "# IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "import os\n",
    "DIR = DATASET_DIR\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "# img = cv2.imread('E:\\\\PHOTOS\\\\Screenshots\\\\panda.png')\n",
    "def horizontal_flip(img, flag):\n",
    "    if flag:\n",
    "        return cv2.flip(img, 1)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def rotation(img, angle):\n",
    "    angle = int(random.uniform(-angle, angle))\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "    img = cv2.warpAffine(img, M, (w, h))\n",
    "    return img\n",
    "\n",
    "def brightness(img, low, high):\n",
    "    value = random.uniform(low, high)\n",
    "    img_float32 = np.float32(img)\n",
    "\n",
    "    hsv = cv2.cvtColor(img_float32, cv2.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype = np.float64)\n",
    "    hsv[:,:,1] = hsv[:,:,1]*value\n",
    "    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
    "    hsv[:,:,2] = hsv[:,:,2]*value \n",
    "    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
    "    hsv = np.array(hsv, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "\n",
    "def channel_shift(img, value):\n",
    "    value = int(random.uniform(-value, value))\n",
    "    img = img + value\n",
    "    img[:,:,:][img[:,:,:]>255]  = 255\n",
    "    img[:,:,:][img[:,:,:]<0]  = 0\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "#############################################################################################################################\n",
    "#############################################################################################################################\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "def frame_nomalize(img):\n",
    "    resized_frame = cv2.resize(img, (64, 64))\n",
    "    normalized_frame = resized_frame / 255\n",
    "    return normalized_frame\n",
    "\n",
    "\n",
    "def frames_extraction(video_path):\n",
    "    '''\n",
    "    This function will extract the required frames from a video after resizing and normalizing them.\n",
    "    Args:\n",
    "        video_path: The path of the video in the disk, whose frames are to be extracted.\n",
    "    Returns:\n",
    "        frames_list: A list containing the resized and normalized frames of the video.\n",
    "    '''\n",
    "\n",
    "    # Declare a list to store video frames.\n",
    "    frames_list = []\n",
    "    \n",
    "    # Read the Video File using the VideoCapture object.\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the total number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Calculate the the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "\n",
    "    # Iterate through the Video Frames.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "\n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "\n",
    "        # Reading the frame from the video. \n",
    "        success, frame = video_reader.read() \n",
    "        \n",
    "\n",
    "        # Check if Video frame is not successfully read then break the loop\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        normalized_frame = frame_nomalize(frame)\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    # Release the VideoCapture object. \n",
    "    video_reader.release()\n",
    "#     print(l1)\n",
    "#     print(l2)\n",
    "\n",
    "    # Return the frames list.\n",
    "    return frames_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "#############################################################################################################################\n",
    "#############################################################################################################################\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# CREATE DATASET WITH DATA AUGMENTATION\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "#############################################################################################################################\n",
    "#############################################################################################################################\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def create_dataset2():\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "    \n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
    "        \n",
    "        # Display the name of the class whose data is being extracted.\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Get the list of video files present in the specific class name directory.\n",
    "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
    "        \n",
    "        # Iterate through all the files present in the files list.\n",
    "        for file_name in files_list:\n",
    "            print(file_name)\n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
    "\n",
    "            # Extract the frames of the video file.\n",
    "            frames = frames_extraction(video_file_path)\n",
    "            \n",
    "            frames_1 = []\n",
    "            frames_2 = []\n",
    "            frames_3 = []\n",
    "            frames_4 = []\n",
    "            frames_5 = []\n",
    "\n",
    "\n",
    "            for i in frames:\n",
    "                \n",
    "# ROTATE\n",
    "                rotate=iaa.Affine(rotate=(-50, 30))\n",
    "                rotated_image=rotate.augment_image(i)\n",
    "#                 nf = frame_nomalize(rotated_image)\n",
    "#                 frames_1.append(nf)\n",
    "                \n",
    "                \n",
    "#                 img = i.astype(np.uint8)\n",
    "#                 gaussian_noise=iaa.AdditiveGaussianNoise(10,20)\n",
    "#                 noise_image=gaussian_noise.augment_image(i)\n",
    "#                 nf = frame_nomalize(noise_image)\n",
    "#                 frames_2.append(nf)\n",
    "                \n",
    "#               crop  \n",
    "                crop = iaa.Crop(percent=(0, 0.3)) # crop image\n",
    "                corp_image=crop.augment_image(rotated_image)\n",
    "                nf = frame_nomalize(corp_image)\n",
    "                frames_1.append(nf)\n",
    "                \n",
    "#                 flip\n",
    "                flip_hr=iaa.Fliplr(p=1.0)\n",
    "                flip_hr_image= flip_hr.augment_image(i)\n",
    "#                 nf = frame_nomalize(flip_hr_image)\n",
    "#                 frames_4.append(nf)\n",
    "\n",
    "#                 contrast\n",
    "                contrast=iaa.GammaContrast(gamma=2.0)\n",
    "                contrast_image =contrast.augment_image(flip_hr_image)\n",
    "                nf = frame_nomalize(contrast_image)\n",
    "                frames_2.append(nf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified above.\n",
    "            # So ignore the vides having frames less than the SEQUENCE_LENGTH.\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "                \n",
    "\n",
    "                # Append the data to their repective lists.\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "                features.append(frames_1)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "                features.append(frames_2)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "#                 features.append(frames_3)\n",
    "#                 labels.append(class_index)\n",
    "#                 video_files_paths.append(video_file_path)\n",
    "\n",
    "#                 features.append(frames_4)\n",
    "#                 labels.append(class_index)\n",
    "#                 video_files_paths.append(video_file_path)\n",
    "\n",
    "    # Converting the list to numpy arrays\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "    \n",
    "    # Return the frames, class index, and video file path.\n",
    "    return features, labels, video_files_paths\n",
    "\n",
    "    \n",
    "features, labels, video_files_paths = create_dataset2()\n",
    "\n",
    "# print(features[0])\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd34f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811008000\n",
      "5\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print((features[0].size))\n",
    "print(features.size)\n",
    "print(features.ndim)\n",
    "print(labels)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa6a2a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228800\n",
      "3686400\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print((features[0].size))\n",
    "print(features.size)\n",
    "print(features.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5bc24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbdjvae\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9e33f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28690936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "MIDDLE\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n",
    "one_hot_encoded_labels = to_categorical(labels)\n",
    "# Split the Data into Train ( 75% ) and Test Set ( 25% ).\n",
    "print(\"MIDDLE\")\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n",
    "                                                                            test_size = 0.20, shuffle = True,\n",
    "                                                                            random_state = seed_constant)\n",
    "\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd654f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038c43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_LRCN_model():\n",
    "    '''\n",
    "    This function will construct the required LRCN model.\n",
    "    Returns:\n",
    "        model: It is the required constructed LRCN model.\n",
    "    '''\n",
    "\n",
    "    # We will use a Sequential model for model construction.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Define the Model Architecture.\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(8, (3, 3), padding='same',activation = 'relu'),\n",
    "                              input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4)))) \n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4))))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "#     model.add(TimeDistributed(Dropout(0.2)))\n",
    "                                      \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "                                      \n",
    "    model.add(LSTM(32))\n",
    "                                      \n",
    "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    # Display the models summary.\n",
    "    model.summary()\n",
    "    \n",
    "    # Return the constructed LRCN model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852cf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510bd46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 500, 64, 64, 8)   224       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 500, 16, 16, 8)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 500, 16, 16, 8)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 500, 16, 16, 16)  1168      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 500, 4, 4, 16)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 500, 4, 4, 16)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 500, 4, 4, 32)    4640      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 500, 2, 2, 32)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 500, 2, 2, 32)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 500, 2, 2, 64)    18496     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 500, 1, 1, 64)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 500, 64)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,043\n",
      "Trainable params: 37,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Created Successfully!\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 369s 15s/step - loss: 1.1443 - accuracy: 0.3214 - val_loss: 1.1204 - val_accuracy: 0.1905\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 25s 1s/step - loss: 1.0920 - accuracy: 0.3690 - val_loss: 1.1120 - val_accuracy: 0.1905\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 31s 1s/step - loss: 1.0891 - accuracy: 0.3690 - val_loss: 1.1200 - val_accuracy: 0.1905\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 1.0973 - accuracy: 0.3690 - val_loss: 1.1263 - val_accuracy: 0.1905\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 1.0922 - accuracy: 0.3690 - val_loss: 1.1150 - val_accuracy: 0.1905\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 1.0903 - accuracy: 0.3690 - val_loss: 1.1162 - val_accuracy: 0.1905\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 29s 1s/step - loss: 1.0889 - accuracy: 0.3690 - val_loss: 1.1166 - val_accuracy: 0.1905\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 29s 1s/step - loss: 1.0993 - accuracy: 0.3690 - val_loss: 1.1121 - val_accuracy: 0.1905\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 29s 1s/step - loss: 1.0868 - accuracy: 0.3690 - val_loss: 1.1221 - val_accuracy: 0.1905\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 30s 1s/step - loss: 1.0922 - accuracy: 0.3214 - val_loss: 1.1152 - val_accuracy: 0.2381\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 29s 1s/step - loss: 1.0863 - accuracy: 0.3333 - val_loss: 1.1318 - val_accuracy: 0.1905\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 29s 1s/step - loss: 1.0861 - accuracy: 0.2976 - val_loss: 1.1190 - val_accuracy: 0.2381\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 1.0853 - accuracy: 0.3690 - val_loss: 1.1342 - val_accuracy: 0.1905\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 32s 2s/step - loss: 1.0853 - accuracy: 0.3333 - val_loss: 1.1262 - val_accuracy: 0.1905\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 33s 2s/step - loss: 1.0721 - accuracy: 0.3095 - val_loss: 1.1352 - val_accuracy: 0.1905\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 33s 2s/step - loss: 1.0673 - accuracy: 0.3810 - val_loss: 1.1142 - val_accuracy: 0.1905\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 34s 2s/step - loss: 1.0470 - accuracy: 0.4286 - val_loss: 1.1797 - val_accuracy: 0.2381\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 34s 2s/step - loss: 1.0392 - accuracy: 0.3333 - val_loss: 1.0940 - val_accuracy: 0.2857\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.0745 - accuracy: 0.3571 - val_loss: 1.0911 - val_accuracy: 0.2857\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 33s 2s/step - loss: 1.0283 - accuracy: 0.4405 - val_loss: 1.1926 - val_accuracy: 0.1905\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 34s 2s/step - loss: 1.0264 - accuracy: 0.3810 - val_loss: 1.1094 - val_accuracy: 0.2381\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 33s 2s/step - loss: 0.9419 - accuracy: 0.5000 - val_loss: 1.2254 - val_accuracy: 0.1905\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 33s 2s/step - loss: 0.9336 - accuracy: 0.4881 - val_loss: 1.4918 - val_accuracy: 0.4286\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 34s 2s/step - loss: 0.8995 - accuracy: 0.4643 - val_loss: 1.2208 - val_accuracy: 0.1905\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 31s 1s/step - loss: 0.8617 - accuracy: 0.5119 - val_loss: 1.3735 - val_accuracy: 0.1905\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.9132 - accuracy: 0.4643 - val_loss: 1.1491 - val_accuracy: 0.5714\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.9194 - accuracy: 0.4643 - val_loss: 1.1728 - val_accuracy: 0.4286\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.8712 - accuracy: 0.5119 - val_loss: 1.4123 - val_accuracy: 0.4286\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.8461 - accuracy: 0.4524 - val_loss: 1.4395 - val_accuracy: 0.4286\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.8291 - accuracy: 0.4762 - val_loss: 1.5156 - val_accuracy: 0.2381\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 29s 1s/step - loss: 0.8110 - accuracy: 0.5357 - val_loss: 1.2615 - val_accuracy: 0.4762\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.8033 - accuracy: 0.5238 - val_loss: 1.1938 - val_accuracy: 0.5238\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7838 - accuracy: 0.5357 - val_loss: 1.3697 - val_accuracy: 0.4762\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7795 - accuracy: 0.4524 - val_loss: 1.7331 - val_accuracy: 0.4286\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7763 - accuracy: 0.5357 - val_loss: 1.8281 - val_accuracy: 0.4286\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7756 - accuracy: 0.5357 - val_loss: 1.8602 - val_accuracy: 0.4286\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 28s 1s/step - loss: 0.7748 - accuracy: 0.5357 - val_loss: 1.9005 - val_accuracy: 0.4286\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7744 - accuracy: 0.5357 - val_loss: 1.9449 - val_accuracy: 0.4286\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7750 - accuracy: 0.5357 - val_loss: 1.9685 - val_accuracy: 0.4286\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7735 - accuracy: 0.5357 - val_loss: 1.9746 - val_accuracy: 0.4286\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 29s 1s/step - loss: 0.7742 - accuracy: 0.4881 - val_loss: 1.9966 - val_accuracy: 0.1905\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7764 - accuracy: 0.4881 - val_loss: 2.0181 - val_accuracy: 0.4286\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7748 - accuracy: 0.5357 - val_loss: 2.0334 - val_accuracy: 0.4286\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7754 - accuracy: 0.4762 - val_loss: 2.0179 - val_accuracy: 0.4286\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7746 - accuracy: 0.5119 - val_loss: 1.9413 - val_accuracy: 0.1905\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7742 - accuracy: 0.5357 - val_loss: 1.9598 - val_accuracy: 0.1905\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7733 - accuracy: 0.5238 - val_loss: 1.9648 - val_accuracy: 0.1905\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7745 - accuracy: 0.4286 - val_loss: 2.0932 - val_accuracy: 0.4286\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.7733 - accuracy: 0.5238 - val_loss: 2.1191 - val_accuracy: 0.1905\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 29s 1s/step - loss: 0.7729 - accuracy: 0.5238 - val_loss: 2.0718 - val_accuracy: 0.4286\n",
      "\n",
      "\n",
      "TASK COMPLETED\n"
     ]
    }
   ],
   "source": [
    "LRCN_model = create_LRCN_model()\n",
    "EPOCHS = 10\n",
    "# Display the success message.\n",
    "print(\"Model Created Successfully!\")\n",
    "# Create an Instance of Early Stopping Callback.\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "# Compile the model and specify loss function, optimizer and metrics to the model.\n",
    "LRCN_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "# Start training the model.\n",
    "# LRCN_model_training_history = LRCN_model.fit(x = features_train, y = labels_train, epochs = 70, batch_size = 4 ,\n",
    "#                                              shuffle = True, validation_split = 0.2)\n",
    "LRCN_model_training_history = LRCN_model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4 ,\n",
    "                                             shuffle = True, validation_split = 0.2)\n",
    "\n",
    "print('\\n\\nTASK COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76001093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 121s 121s/step - loss: 2.1719 - accuracy: 0.2593\n",
      "model is saved\n"
     ]
    }
   ],
   "source": [
    "# save  model\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "# test and save  model accuracy\n",
    "model_evaluation_history = LRCN_model.evaluate(features_test, labels_test)\n",
    "# Get the loss and accuracy from model_evaluation_history.\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "    \n",
    "model_file_name = \"E:\\\\test_output\\\\augmentation_final__model_500_15_(aug_2).h5\"\n",
    "\n",
    "# Save the Model.\n",
    "LRCN_model.save(model_file_name)\n",
    "new_model = load_model(model_file_name)\n",
    "print(\"model is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a474da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sn \n"
     ]
    }
   ],
   "source": [
    "print(\"sn \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4ae1cfd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter path : E:\\\\test_output\\\\sn2.mp4\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n"
     ]
    }
   ],
   "source": [
    "def predict_on_video(video_file_path, output_file_path, SEQUENCE_LENGTH):\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "#     model_file_name = \"E:\\\\test_output\\\\final__model.h5\"\n",
    "    model_file_name = \"E:\\\\test_output\\\\augmentation_final__model_250_15.h5\"\n",
    "\n",
    "    new_model = load_model(model_file_name)\n",
    "\n",
    "    '''\n",
    "    This function will perform action recognition on a video using the LRCN model.\n",
    "    Args:\n",
    "    video_file_path:  The path of the video stored in the disk on which the action recognition is to be performed.\n",
    "    output_file_path: The path where the ouput video with the predicted action being performed overlayed will be stored.\n",
    "    SEQUENCE_LENGTH:  The fixed number of frames of a video that can be passed to the model as one sequence.\n",
    "    '''\n",
    "    \n",
    "    # Initialize the VideoCapture object to read from the video file.\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    # Get the width and height of the video.\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Declare a queue to store video frames.\n",
    "    frames_queue = deque(maxlen = SEQUENCE_LENGTH)\n",
    "\n",
    "    # Initialize a variable to store the predicted action being performed in the video.\n",
    "    predicted_class_name = ''\n",
    "\n",
    "    # Iterate until the video is accessed successfully.\n",
    "    while video_reader.isOpened():\n",
    "\n",
    "        # Read the frame.\n",
    "        ok, frame = video_reader.read() \n",
    "        \n",
    "        # Check if frame is not read properly then break the loop.\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1.\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        # Appending the pre-processed frame into the frames list.\n",
    "        frames_queue.append(normalized_frame)\n",
    "\n",
    "        # Check if the number of frames in the queue are equal to the fixed sequence length.\n",
    "        if len(frames_queue) == SEQUENCE_LENGTH:\n",
    "\n",
    "            # Pass the normalized frames to the model and get the predicted probabilities.\n",
    "            predicted_labels_probabilities = new_model.predict(np.expand_dims(frames_queue, axis = 0))[0]\n",
    "\n",
    "\n",
    "            # Get the index of class with highest probability.\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "#             print(\"predicted_labels_probabilities : \",predicted_label)\n",
    "\n",
    "\n",
    "            # Get the class name using the retrieved index.\n",
    "            predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "\n",
    "    video_reader.release()\n",
    "    return predicted_class_name\n",
    "        # Write predicted class name on top of the frame.\n",
    "#         cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "#         # Write The frame into the disk using the VideoWriter Object.\n",
    "#         video_writer.write(frame)\n",
    "        \n",
    "#     # Release the VideoCapture and VideoWriter objects.\n",
    "#      video_writer.release()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##########################################################33\n",
    "\n",
    "import cv2\n",
    "import collections\n",
    "from collections import *\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "\n",
    "SEQUENCE_LENGTH = 250\n",
    "# Construct the output video path.\n",
    "output_video_file_path = \"E:\\\\test_output\\\\o1.mp4\"\n",
    "path = str(input(\"Enter path : \"))\n",
    "# Perform Action Recognition on the Test Video.\n",
    "exercise = predict_on_video(path, output_video_file_path, SEQUENCE_LENGTH)\n",
    "\n",
    "# Display the output video.\n",
    "# VideoFileClip(output_video_file_path, audio=False, target_resolution=(300,None)).ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e552554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "de55c798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'suryanamaskar'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "78a44d1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-92992bbb2e02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexercise\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"suryanamaskar\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcount_suryanamaskar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexercise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-189-92992bbb2e02>\u001b[0m in \u001b[0;36mcount_suryanamaskar\u001b[1;34m(exercise, path)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[1;31m# Recolor image to RGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------- COUNTER--------------------------------------------------------------\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "\n",
    "\n",
    "def calculate_angle_squat(a,b,c):\n",
    "        a = np.array(a) # First\n",
    "        b = np.array(b) # Mid\n",
    "        c = np.array(c) # End\n",
    "\n",
    "        radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "        angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "        if angle >180.0:\n",
    "            angle = 360-angle\n",
    "\n",
    "        return angle \n",
    "    \n",
    "# ##############################################################################################################################\n",
    "# ##############################################################################################################################\n",
    "\n",
    "def count_squat(exercise, path):\n",
    "    # render angel in vedio\n",
    "    # squat\n",
    "    # final counter\n",
    "    import cv2\n",
    "    stage = \"up\"\n",
    "\n",
    "    \n",
    "\n",
    "    # ///////////////////////\n",
    "    cap = cv2.VideoCapture(path)\n",
    "#     cap = cv2.VideoCapture(\"C:\\\\Users\\\\abc-pc\\\\Downloads\\\\Exercise\\\\squat\\\\video_squat_16.mp4\")\n",
    "    counter = 0 \n",
    "    stage = None\n",
    "\n",
    "    ## Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    # Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "\n",
    "                l_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                l_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "                l_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "                r_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "                r_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "                r_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "\n",
    "\n",
    "                # Calculate angle\n",
    "                angle_l = calculate_angle_squat(l_hip, l_knee, l_ankle)\n",
    "                angle_r = calculate_angle_squat(r_hip, r_knee, r_ankle)\n",
    "\n",
    "    #             print(\"Left : \",angle_l)\n",
    "    #             print(\"Right : \",angle_r)\n",
    "\n",
    "    #             angle = str(angle_l) +\" : \"+ str(angle_r)\n",
    "                angle_up = min(angle_l,angle_r)\n",
    "    #             print(angle)\n",
    "    \n",
    "#     count set\n",
    "                if angle_up > 160:\n",
    "                    stage = \"up\"\n",
    "                if angle_up < 150 and stage == \"up\":\n",
    "                    stage=\"down\"\n",
    "                    counter +=1\n",
    "                    print(counter)\n",
    "                info = \"Set : \" + str(counter)\n",
    "                e = exercise\n",
    "\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                org = (50, 50)\n",
    "                fontScale = 1\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 2\n",
    "                image = cv2.putText(image, info, [100,100], font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                image = cv2.putText(image, e, [100,200], font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(0,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(0,66,230), thickness=2, circle_radius=2) \n",
    "                                     )               \n",
    "\n",
    "            b = cv2.resize(image,(600,600))\n",
    "            cv2.imshow('Mediapipe Feed', b)\n",
    "            \n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# ##############################################################################################################################\n",
    "# ##############################################################################################################################\n",
    "\n",
    "        \n",
    "def count_pushup(exercise, path):\n",
    "    # render angel in vedio\n",
    "    # pushup\n",
    "    # final counter\n",
    "\n",
    "    stage = \"up\"\n",
    "    l = []\n",
    "    def calculate_angle_squat(a,b,c):\n",
    "        a = np.array(a) # First\n",
    "        b = np.array(b) # Mid\n",
    "        c = np.array(c) # End\n",
    "\n",
    "        radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "        angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "        if angle >180.0:\n",
    "            angle = 360-angle\n",
    "\n",
    "        return angle \n",
    "\n",
    "\n",
    "    # ///////////////////////\n",
    "#     cap = cv2.VideoCapture(\"C:\\\\Users\\\\abc-pc\\\\Downloads\\\\Exercise\\\\pushup\\\\video_pushup_12.mp4\")\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    counter = 0 \n",
    "    stage = None\n",
    "\n",
    "    ## Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    # Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "\n",
    "                l_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                l_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                l_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "                r_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                r_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "                r_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "\n",
    "\n",
    "                # Calculate angle\n",
    "                angle_l = calculate_angle_squat(l_shoulder, l_elbow, l_wrist)\n",
    "                angle_r = calculate_angle_squat(r_shoulder, r_elbow, r_wrist)\n",
    "\n",
    "    # #             print(\"Left : \",angle_l)\n",
    "    # #             print(\"Right : \",angle_r)\n",
    "\n",
    "    #             angle = str(angle_l) +\" : \"+ str(angle_r)\n",
    "                angle_up = min(angle_l,angle_r)\n",
    "    #             print(angle_up)\n",
    "                if angle_up > 150:\n",
    "                    stage = \"up\"\n",
    "                if angle_up < 100 and stage == \"up\":\n",
    "                    stage=\"down\"\n",
    "                    counter +=1\n",
    "                    \n",
    "                info = \"Set : \" + str(counter)\n",
    "                e = exercise\n",
    "\n",
    "\n",
    "                l.append(angle_up)\n",
    "\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                org = (50, 50)\n",
    "                fontScale = 3\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 3\n",
    "                image = cv2.putText(image, info, [100,100], font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                image = cv2.putText(image, e, [100,200], font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(0,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(0,66,230), thickness=2, circle_radius=2) \n",
    "                                     )               \n",
    "\n",
    "            b = cv2.resize(image,(500,500))\n",
    "            cv2.imshow('Mediapipe Feed', b)\n",
    "            \n",
    "\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "#     print(\"min_angle\",min(l))\n",
    "#     print(\"max_angle\",max(l))\n",
    "    \n",
    "# count_squat()\n",
    "# count_pushup()\n",
    "\n",
    "\n",
    "def calculate_angle_squat(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "\n",
    "\n",
    "# ///////////////////////\n",
    "def count_suryanamaskar(exercise, path):\n",
    "    # render angel in vedio\n",
    "    # squat\n",
    "    # final counter\n",
    "    import cv2\n",
    "    stage = \"up\"\n",
    "\n",
    "    \n",
    "\n",
    "    # ///////////////////////\n",
    "    cap = cv2.VideoCapture(path)\n",
    "#     cap = cv2.VideoCapture(\"C:\\\\Users\\\\abc-pc\\\\Downloads\\\\Exercise\\\\squat\\\\video_squat_16.mp4\")\n",
    "    counter = 0 \n",
    "    stage = None\n",
    "\n",
    "    ## Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    # Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "\n",
    "                l_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                l_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                l_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "\n",
    "                l_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                l_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "                l_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "\n",
    "                r_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "                r_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "                r_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "                wha = calculate_angle_squat(l_wrist, l_hip, l_ankle)\n",
    "                sha = calculate_angle_squat(l_shoulder, l_hip, l_ankle)\n",
    "#                 wha = format(wha,\".0f\")\n",
    "#                 sha = format(sha,\".0f\")\n",
    "\n",
    "\n",
    "                if  wha >=165 and stage == \"up\":\n",
    "                    stage = \"down\"\n",
    "                if  wha >=165 and stage == \"down\":\n",
    "                    stage = \"up\"\n",
    "                    counter += 1\n",
    "\n",
    "                info = \"Set : \" + str(counter)\n",
    "                e = exercise\n",
    "\n",
    "\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                org = (50, 50)\n",
    "                fontScale = 1\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 2\n",
    "                image = cv2.putText(image, info, [100,50], font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                image = cv2.putText(image, e, [10,100], font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(0,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(0,66,230), thickness=2, circle_radius=2) \n",
    "                                     )               \n",
    "\n",
    "            b = cv2.resize(image,(600,600))\n",
    "            cv2.imshow('Mediapipe Feed', b)\n",
    "            \n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# ##############################################################################################################################\n",
    "# ##############################################################################################################################\n",
    "\n",
    "if exercise == \"squat\":\n",
    "    count_squat(exercise,path)\n",
    "if exercise == \"pushups\":\n",
    "    count_pushup(exercise,path)    \n",
    "\n",
    "if exercise == \"suryanamaskar\":\n",
    "    count_suryanamaskar(exercise,path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e24ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e227e1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a045e919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82eb43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c491db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
